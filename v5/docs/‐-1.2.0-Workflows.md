<TABLE width="100%"><TR><TD align="left"><a href="‐-1.1.1-Setups.md">PREV < 1.1.1 Setups</a></TD><TD align="right"><a href="‐-1.2.5-Scripts.md">1.2.5 Scripts > NEXT</a></TD></TR></TABLE>

```
|----- .github/                              # FOLDER - Configuration and workflows directory
|-------- workflows                          # FOLDER - workflows
|---------- dataworkflow.yml                 # FILE - Copies updates/data.json to root path
|---------- generate_core_graph.yml          # FILE - Scans key folders and generates your core graph
|---------- generate_mini_graphs.yml         # FILE - Scans your core graph and creates smaller mini graphs, and creates registry.json
|---------- generate_cache_graph.yml         # FILE - Scans context session files and creates theme.registry.json
|---------- generate_cognitive_graph_map.yml # FILE - This is a wrapper workflow that runs all three core, mini, and cache graph workflows
|---------- rootdata_updated.yml             # FILE - Create archive of root data.json ** see note
```

# DATAWORKFLOW

### Workflow: Data Workflow  
**Filename**: `dataworkflow.yml`  

#### Purpose:  
The Data Workflow is designed to monitor changes to the `data.json` file in the `updates/` directory and ensure those updates are appropriately validated, archived, and synced with the root directory. This workflow also automates the cleanup of old files and provides notifications of workflow results.

#### Key Features:
1. **Triggering Events**:
   - Executes automatically when `updates/data.json` is modified and pushed to the repository.
   - Can also be triggered manually using the `workflow_dispatch` option.

2. **Core Workflow Steps**:
   - **Step 1: Repository Checkout**  
     The workflow retrieves the full history of the repository to ensure access to all necessary files.
   - **Step 2: Git Configuration**  
     Configures Git with the bot’s credentials to enable committing and pushing changes back to the repository.
   - **Step 3: JSON Validation**  
     Runs a Python script (`validate_json.py`) to ensure that `data.json` adheres to expected JSON formatting standards.
   - **Step 4: Apply Template**  
     Applies predefined templates to `data.json` using `apply_template.py` to maintain data consistency and formatting.
   - **Step 5: Copy and Archive Data**  
     - Copies `updates/data.json` to the repository root as `data.json`.
     - Archives the file into an `archive/` directory with a timestamp for versioning.
   - **Step 6: Commit and Push Changes**  
     Updates are staged, committed, and pushed to the remote repository if the workflow is not in dry-run mode.
   - **Step 7: Debug Archive State**  
     Lists all files in the `archive/` directory to confirm the success of the archiving process.
   - **Step 8: Cleanup and Removal**  
     Deletes `updates/data.json` after processing and invokes a cleanup script (`cleanup_purge.py`) to remove outdated files.
   - **Step 9: Notifications**  
     Sends the workflow status as a GitHub issue, detailing successes or failures.
   - **Step 10: Notification Log Generation**  
     Creates or updates a log file summarizing the results of the workflow.
   - **Step 11: Debug Workflow State**  
     Outputs the Git repository status and displays the `.gitignore` file for debugging purposes.

#### Parameters and Environment Variables:
- **`DRYRUN`**: Controls whether the workflow operates in a simulation mode. If `true`, changes are logged but not applied.
- **`CLEANUP_PERIOD`**: Defines the timeframe for removing older files during the cleanup process.

#### Notifications:
Notifications are sent using GitHub issues to alert about the workflow’s success or failure. The content of the notification includes detailed logs, which are stored in the repository for reference.

#### Practical Notes:
- The workflow ensures data integrity through validation and templating, providing consistency across all updates.
- Archiving with timestamps allows for traceability of changes, aiding in debugging and historical analysis.
- The cleanup process ensures repository hygiene by removing outdated files.


# GENERATE_CORE_GRAPH

### Workflow: Generate Core Graph  
**Filename**: `generate_core_graph.yml`  

#### Purpose:  
The Generate Core Graph workflow is a vital component of **Project MyShelf**, responsible for scanning key repository folders and generating the **core graph**, a structured representation of the project's interconnected elements. This workflow ensures that relationships between data and components are accurately mapped, forming the foundation for further graph analysis and visualization.

---

#### Key Features:
1. **Manual Triggering**:
   - The workflow can be initiated manually via GitHub's `workflow_dispatch` feature.
   - Users can optionally include a reason for triggering the workflow, providing context for each run.

2. **Core Workflow Steps**:
   - **Step 1: Repository Checkout**  
     The workflow retrieves the complete repository history to ensure all files and metadata are accessible for processing.
   - **Step 2: Git Configuration**  
     Configures Git with the bot’s credentials, enabling the workflow to commit and push changes.
   - **Step 3: Debug Initial Directory Structure**  
     Lists the repository's directory structure, including relevant `.json` files, to provide context for the workflow's starting state.
   - **Step 4: Python Environment Setup**  
     Installs Python 3.9 and necessary dependencies for graph generation, such as:
     - **networkx** for graph data structures.
     - **spaCy** for natural language processing.
     - **scikit-learn** for analytical tasks.
   - **Step 5: spaCy Model Verification**  
     Downloads and validates the **en_core_web_sm** language model, ensuring NLP tasks can run smoothly.
   - **Step 6: Locate and Validate `index.json`**  
     Searches for the `index.json` file in the repository, a critical input for graph generation. If not found, the workflow halts and logs the issue.
   - **Step 7: Core Graph Generation**  
     Executes the `generate_core_graph.py` script, which processes the repository's data to generate a new **core.graph.json** file. Errors are logged if the script fails.
   - **Step 8: Commit and Push Changes**  
     Stages and commits updates to the graph files:
     - **core.graph.json**: The newly generated graph.
     - **core.graph.json.old**: A backup of the previous graph.
     Changes are then pushed to the repository.
   - **Step 9: Notifications**  
     If the workflow fails, a GitHub issue is automatically created with detailed logs of the error.
   - **Step 10: Debug Workflow State**  
     Outputs the Git repository status and checks the contents of `.gitignore` to ensure proper handling of ignored files.

---

#### Environment Variables:
- **`DRYRUN`**: Not utilized directly in this workflow but can be added for simulation purposes.
- **`GITHUB_TOKEN`**: A secure token used to authenticate Git operations and create notifications.

#### Notifications:
When the workflow encounters errors, a detailed issue is created in the repository using the **peter-evans/create-issue-from-file** action. The issue contains logs to help diagnose and resolve the problem.

---

#### Practical Notes:
- **Dependency Management**: Installing and verifying Python libraries and spaCy models ensures a smooth execution of graph generation tasks.
- **Traceability**: By archiving previous graph versions as `core.graph.json.old`, the workflow maintains a clear history of changes.
- **Error Handling**: Rigorous checks, such as verifying the presence of `index.json`, prevent incomplete or invalid graph outputs.

This workflow is the backbone of the **core graph generation** process, ensuring that Project MyShelf's graph data is always accurate, up-to-date, and ready for downstream workflows.


# GENERATE_MINI_GRAPH

### Workflow: Generate Mini Graphs  
**Filename**: `generate_mini_graphs.yml`  

#### Purpose:  
The Generate Mini Graphs workflow is designed to process the core graph and produce smaller, specialized graphs (mini-graphs) that represent subsets of the data. It also creates an organized registry (`registry.json`) and an index (`index.json`) for managing these mini-graphs efficiently. This workflow enables easier analysis and management of interconnected data by breaking down the core graph into more manageable components.

---

#### Key Features:
1. **Manual Triggering**:
   - The workflow can be initiated manually via the `workflow_dispatch` event.
   - A reason for the trigger can optionally be provided, offering context for the run.

2. **Core Workflow Steps**:
   - **Step 1: Repository Checkout**  
     Fetches the complete repository, ensuring access to all files required for graph processing.
   - **Step 2: Git Configuration**  
     Configures Git credentials to enable commits and pushes to the repository.
   - **Step 3: Debug Directory Structure**  
     Outputs the directory structure to confirm the location of relevant files such as `core.graph.json`.
   - **Step 4: Python Environment Setup**  
     Installs Python 3.9 and required libraries, including:
     - **networkx** for graph operations.
     - **spaCy** for natural language processing.
     - **scikit-learn** for analytical tasks.
   - **Step 5: Dependency Validation**  
     Verifies that Python packages and spaCy models are correctly installed.
   - **Step 6: Validate `core.graph.json`**  
     Confirms the presence of the core graph file (`core.graph.json`) as input for mini-graph generation.
   - **Step 7: Mini-Graph Generation**  
     Runs the `generate_mini_graphs.py` script to produce the mini-graphs from the core graph. Any errors during this process are logged.
   - **Step 8: Graph Registry Creation**  
     Executes `generate_graph_registry.py` to generate a registry file (`registry.json`) for managing the mini-graphs.
   - **Step 9: Validate `index.json`**  
     Ensures that the mini-graph index (`index.json`) is successfully created as part of the workflow.
   - **Step 10: Commit and Push Changes**  
     Stages, commits, and pushes the updated mini-graph files (`*.graph.json`), the registry file (`registry.json`), and the index file (`index.json`) to the repository.
   - **Step 11: Notifications**  
     If the workflow fails, a GitHub issue is created with detailed logs to assist in diagnosing and resolving the error.
   - **Step 12: Debug Workflow State**  
     Outputs the repository’s Git status and checks for the presence of a `.gitignore` file for debugging purposes.

---

#### Environment Variables:
- **`GITHUB_TOKEN`**: Used to authenticate Git operations and create notifications.
- **`DRYRUN`**: Can optionally be integrated to simulate actions without making changes.

#### Notifications:
If the workflow encounters errors, a GitHub issue is generated using the **peter-evans/create-issue-from-file** action. Logs are included to facilitate troubleshooting.

---

#### Practical Notes:
- **Data Traceability**: The workflow maintains an organized structure by generating mini-graphs, a registry, and an index, which together provide a comprehensive overview of the dataset.
- **Error Prevention**: Validation steps (e.g., checking for `core.graph.json` and ensuring `index.json` creation) safeguard against incomplete or invalid results.
- **Scalability**: By breaking down the core graph into smaller components, the workflow enhances the project’s scalability and facilitates targeted analysis.

This workflow is essential for managing and processing complex graph data in Project MyShelf, ensuring clarity and organization across all datasets.


# GENERATE_CACHE_GRAPH

### Workflow: Generate Cache Graph  
**Filename**: `generate_cache_graph.yml`  

#### Purpose:  
The Generate Cache Graph workflow creates a specialized graph based on session context data, resulting in a cache graph. This workflow ensures that contextual data is organized into smaller, theme-based graphs and indexed for efficient retrieval and analysis. It also maintains a registry for all cache graphs generated.

---

#### Key Features:
1. **Manual Triggering**:
   - The workflow can be triggered manually through the `workflow_dispatch` event.
   - Users can optionally provide a reason for the trigger, offering clarity on the workflow's purpose.

2. **Core Workflow Steps**:
   - **Step 1: Repository Checkout**  
     Retrieves the complete repository, ensuring access to all necessary files and metadata.
   - **Step 2: Git Configuration**  
     Configures Git credentials to enable pushing updates back to the repository.
   - **Step 3: Debug Directory Structure**  
     Outputs the directory structure, listing relevant files such as JSON, Python, and Markdown, to validate the repository setup.
   - **Step 4: Python Environment Setup**  
     Installs Python 3.9 and necessary libraries, including:
     - **networkx** for graph operations.
     - **spaCy** for natural language processing.
     - **scikit-learn** for data analysis.
   - **Step 5: Dependency Validation**  
     Verifies that Python dependencies and spaCy models are properly installed to avoid runtime errors.
   - **Step 6: Validate Context Path**  
     Confirms the presence of the `context` directory, which stores session data. If missing, the workflow halts and logs the issue.
   - **Step 7: Cache Graph Generation**  
     - Ensures the `snapshots/mini-graph-themes` directory exists for storing output files.
     - Executes the `generate_cache_graph.py` script to process context session files and generate cache graphs. Errors are logged if the script fails.
   - **Step 8: Commit and Push Changes**  
     Stages, commits, and pushes updated files, including:
     - `theme.registry.json`: A registry of all theme-based graphs.
     - `context.session.*.theme.graph.json`: Individual theme-based graphs.
     - `index.json`: The index file for theme-based graphs.
   - **Step 9: Notifications**  
     In case of workflow failure, a detailed GitHub issue is created using the **peter-evans/create-issue-from-file** action, with logs to aid troubleshooting.
   - **Step 10: Debug Workflow State**  
     Outputs the current Git repository status and `.gitignore` contents to assist in debugging any issues.

---

#### Environment Variables:
- **`GITHUB_TOKEN`**: A secure token used to authenticate Git operations and issue notifications.

#### Notifications:
If the workflow encounters an error, a GitHub issue is automatically created. This issue includes logs detailing the failure, allowing for efficient diagnosis and resolution.

---

#### Practical Notes:
- **Data Organization**: By creating theme-based graphs, the workflow enhances the organization and accessibility of session context data.
- **Error Handling**: The validation of dependencies, paths, and directories ensures that the workflow runs smoothly and halts if key prerequisites are missing.
- **Traceability**: Registry and index files maintain a clear record of all generated cache graphs, making it easier to track updates.

This workflow plays a critical role in processing and structuring session data for Project MyShelf, enabling efficient theme-based graph analysis and integration with other workflows.


# GENERATE_COGNITIVE_GRAPH_MAP

### Workflow: MyShelf Workflow Orchestrator  
**Filename**: `myshelf_workflow_orchestrator.yml`  

#### Purpose:  
The MyShelf Workflow Orchestrator is a centralized workflow designed to coordinate and manage the execution of other workflows—**Core Graph**, **Mini Graphs**, and **Cache Graph**—individually or in sequence. This workflow enables users to streamline and monitor the interdependent processes within Project MyShelf with precision and flexibility.

---

#### Key Features:
1. **Manual Triggering with Module Selection**:
   - The orchestrator is initiated manually using the `workflow_dispatch` event.
   - Users can specify which module(s) to execute using the `module` input:
     - **`all`**: Executes all workflows (Core, Mini, and Cache) in sequence.
     - **`core`**: Triggers only the Core Graph workflow.
     - **`mini`**: Triggers only the Mini Graphs workflow.
     - **`cache`**: Triggers only the Cache Graph workflow.

2. **Centralized Workflow Management**:
   - Orchestrates the triggering and monitoring of dependent workflows, ensuring efficient execution.
   - Uses environment variables (`CORE_GRAPH_WORKFLOW_ID`, `MINI_GRAPHS_WORKFLOW_ID`, `CACHE_GRAPH_WORKFLOW_ID`) to dynamically reference the workflow IDs for triggering.

3. **Core Workflow Steps**:
   - **Step 1: Core Graph Workflow**  
     - If the module is set to `all` or `core`, the orchestrator triggers the Core Graph workflow and polls its status until it completes or fails.
     - The polling mechanism checks the workflow status every 30 seconds (increasing by 10 seconds after each retry) and retries up to 10 times.
   - **Step 2: Mini Graphs Workflow**  
     - If the module is set to `all` or `mini`, and the Core Graph workflow completes successfully, the orchestrator triggers the Mini Graphs workflow.
     - Similar to the Core Graph workflow, it polls the Mini Graphs workflow for completion or failure.
   - **Step 3: Cache Graph Workflow**  
     - If the module is set to `all` or `cache`, and the Mini Graphs workflow completes successfully, the orchestrator triggers the Cache Graph workflow.
     - The polling mechanism ensures that the Cache Graph workflow status is monitored until completion or failure.

4. **Dynamic Status Polling**:
   - The orchestrator uses GitHub API requests to poll the status of each workflow.
   - If a workflow fails or exceeds the maximum polling retries, the orchestrator exits with a failure message.

5. **Error Handling**:
   - Failure of any workflow halts the subsequent steps and exits with detailed error logs.
   - Includes robust retry logic and dynamic polling intervals to handle unexpected delays.

---

#### Environment Variables:
- **`CORE_GRAPH_WORKFLOW_ID`**: The workflow ID for the Core Graph workflow.
- **`MINI_GRAPHS_WORKFLOW_ID`**: The workflow ID for the Mini Graphs workflow.
- **`CACHE_GRAPH_WORKFLOW_ID`**: The workflow ID for the Cache Graph workflow.
- **`GITHUB_TOKEN`**: Used for authenticating GitHub API requests.

---

#### Practical Notes:
- **Modular Flexibility**: Users can run all workflows sequentially or focus on a specific module based on project needs.
- **Centralized Control**: This workflow consolidates and automates interdependent workflows, reducing manual intervention and improving efficiency.
- **Scalability**: The orchestrator is designed to scale with Project MyShelf’s growing complexity, providing a robust framework for managing multiple workflows.

#### Notifications:
The orchestrator logs the status of all triggered workflows, ensuring visibility into the entire process. Users are notified in case of failures, allowing quick resolution of issues.

---

This workflow serves as the command center for Project MyShelf’s operational workflows, providing structure, flexibility, and efficiency to the entire process.


# ROOTDATA_UPDATED

### Workflow: Root Data Updated  
**Filename**: `rootdata_updated.yml`

#### Purpose  
The **Root Data Updated** workflow ensures the integrity, backup, and validation of the critical `data.json` file at the root level of your repository. It safeguards against accidental data corruption by validating and archiving the file before updates, while providing detailed error reporting for transparency.

---

#### Key Features  

1. **Manual Triggering**  
   - The workflow is initiated via GitHub’s `workflow_dispatch` event, enabling manual execution.  
   - Users can provide a reason for triggering the workflow for documentation purposes.  

2. **Validation and Backup Process**  
   - **Repository Checkout**: Fetches the repository with complete history to ensure file accessibility.  
   - **Validation**: Executes a validation script (`validate_root_json.py`) to confirm the file adheres to expected JSON standards.  
   - **Backup**: Creates a timestamped archive of the `data.json` file, preserving a historical version for rollback or analysis.  

3. **Error Handling and Notifications**  
   - If an error occurs during any step, the workflow logs the issue and generates a GitHub issue with detailed information.  
   - Error notifications are sent directly via GitHub Issues, ensuring swift problem resolution.  

4. **Archive Debugging**  
   - The workflow lists and verifies the contents of the archive directory, confirming that backups were successfully created.  

---

#### Steps in Detail  

1. **Checkout Repository**  
   The repository is fully checked out, ensuring all files and history are accessible for validation and backup operations.  

2. **Validate `data.json`**  
   - Ensures the `data.json` file exists at the root of the repository.  
   - Uses the validation script to verify that the file conforms to the required JSON schema.  

3. **Backup `data.json`**  
   - Archives the `data.json` file in a directory named `archive` with a timestamp for traceability.  
   - This ensures that a snapshot of the current file is preserved before applying any updates.  

4. **Commit and Push Changes**  
   - The archived file is staged, committed, and pushed to the `main` branch of the repository.  
   - Error handling is implemented to ensure no changes are lost due to Git operation failures.  

5. **Notifications via GitHub Issues**  
   - If any step in the workflow fails, a GitHub issue is created using the **peter-evans/create-issue-from-file** action.  
   - Detailed error logs are attached for quick troubleshooting.  

6. **Debug Archive State**  
   - The archive directory’s contents are listed at the end of the workflow to verify the backup’s success.  

---

#### Benefits  

- **Data Security**: Ensures the integrity of the root-level `data.json` file by validating its structure and maintaining a secure backup.  
- **Traceability**: Timestamped backups provide historical snapshots of critical files, aiding in rollback and analysis.  
- **Error Visibility**: GitHub notifications and detailed logs help identify and resolve issues quickly.  

This workflow is a cornerstone for maintaining the reliability and security of your repository’s core data files. By automating validation and archiving, it eliminates risks associated with manual processes and ensures a clear record of changes.


# RETRIEVING WORKFLOW ID

Once you have added all of your workflows into place, you will noticed that the generate_cognitive_graph_map (orchestrator) requires workflow id of the child workflows. There are two ways to accomplish this. The easy way and the "I want to learn how to do it myself".

## EASY

When you get around to installing the Open API schema into the custom GPT you will expose access to Workflows. You can ask your AI Assistant to retrieve the workflow ids. NICE! Once you have all three IDs then update the orchestrator accordingly.

`retrieve workflow ID for "rootdata_updated"`

Response; 

```
The workflow ID for **`rootdata_updated`** is **`123456789`**.
```


## TEACH ME

To retrieve the workflow ID for a specific workflow in a GitHub repository using the GitHub API, you can use the following endpoint:

### GitHub API Endpoint
```
GET /repos/{owner}/{repo}/actions/workflows
```

### Steps
1. Replace `{owner}` with the owner of the repository.
2. Replace `{repo}` with the name of the repository.

This endpoint lists all workflows in the repository, including their `id` and `name`.

### Example cURL Command
```bash
curl -X GET \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer YOUR_GITHUB_TOKEN" \
  https://api.github.com/repos/{owner}/{repo}/actions/workflows
```

### Key Details
- The response will include details of all workflows in the repository. Look for the workflow you are interested in by its `name` and extract the `id` field.
- The `Authorization` header must include a valid GitHub personal access token (PAT) with `repo` or `workflow` permissions.

### Sample Response
```json
{
  "total_count": 2,
  "workflows": [
    {
      "id": 12345678,
      "node_id": "MDg6V29ya2Zsb3cxMjM0NTY3OA==",
      "name": "Core Graph Workflow",
      "path": ".github/workflows/core_graph_workflow.yml",
      "state": "active",
      "created_at": "2023-01-01T00:00:00Z",
      "updated_at": "2023-01-01T00:00:00Z",
      "url": "https://api.github.com/repos/{owner}/{repo}/actions/workflows/12345678"
    },
    {
      "id": 87654321,
      "node_id": "MDg6V29ya2Zsb3cxMjM0NTY3OA==",
      "name": "Mini Graph Workflow",
      "path": ".github/workflows/mini_graph_workflow.yml",
      "state": "active",
      "created_at": "2023-01-02T00:00:00Z",
      "updated_at": "2023-01-02T00:00:00Z",
      "url": "https://api.github.com/repos/{owner}/{repo}/actions/workflows/87654321"
    }
  ]
}
```

### Extracting Workflow ID
From the response, find the workflow by its name (`Core Graph Workflow`, for example) and note the `id` (e.g., `12345678`).




<TABLE width="100%"><TR><TD align="left"><a href="‐-1.1.1-Setups.md">PREV < 1.1.1 Setups</a></TD><TD align="right"><a href="‐-1.2.5-Scripts.md">1.2.5 Scripts > NEXT</a></TD></TR></TABLE>
